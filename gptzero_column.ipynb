{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = r\"D:\\data\\claim_identification_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = pd.read_excel(os.path.join(DATADIR, \"essay_scores.xlsx\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay(filename):\n",
    "    df = pd.read_csv(os.path.join(DATADIR, \"Data\", filename + \".csv\"))\n",
    "\n",
    "    res = []\n",
    "\n",
    "    ind_para = 1\n",
    "    while ind_para < len(df):\n",
    "        this_para = df['discourse_part'] == \"Paragraph_\" + str(ind_para)\n",
    "        if not any(this_para):\n",
    "            break\n",
    "        text = ' '.join(df['discourse_text'][this_para])\n",
    "        res.append(text)\n",
    "        ind_para += 1\n",
    "    \n",
    "    return '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays['Text'] = essays['Essay'].apply(get_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4273"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(essays['Text'].apply(len))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Essays by Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = []\n",
    "\n",
    "for i, row in essays.iterrows():\n",
    "    try:\n",
    "        filepath = f\"{DATADIR}/Data/{row['Essay']}.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    df['essay'] = row['Essay']\n",
    "    df['score'] = row['Holistic Score']\n",
    "\n",
    "    all_essays.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_part</th>\n",
       "      <th>discourse_boundary</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>adjudicated_discourse_type</th>\n",
       "      <th>adjudicated_effectiveness</th>\n",
       "      <th>adjudicated_hierarchical</th>\n",
       "      <th>adjudicated_parallel</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_MSU_essay|Paragraph_1|Nonannotated|0,20</td>\n",
       "      <td>Paragraph_1</td>\n",
       "      <td>(0, 20)</td>\n",
       "      <td>Heroes or Celebrities</td>\n",
       "      <td>Nonannotated</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_MSU_essay|Paragraph_2|Nonannotated|0,565</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(0, 565)</td>\n",
       "      <td>Celebrities and heroes are often confused in t...</td>\n",
       "      <td>Nonannotated</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_MSU_essay|Paragraph_2|Final_Claim|567,660</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(567, 660)</td>\n",
       "      <td>This idea of a hero has been forgotten and sho...</td>\n",
       "      <td>Final_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_MSU_essay|Paragraph_3|Data|0,519</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(0, 519)</td>\n",
       "      <td>How does one define a hero? Is it because of t...</td>\n",
       "      <td>Data</td>\n",
       "      <td>effective</td>\n",
       "      <td>Paragraph_3|Primary_Claim|521,628</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_MSU_essay|Paragraph_3|Primary_Claim|521,628</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(521, 628)</td>\n",
       "      <td>Although many people do heroic things, they ar...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>effective</td>\n",
       "      <td>Paragraph_2|Final_Claim|567,660</td>\n",
       "      <td>Paragraph_4|Primary_Claim|449,553</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>9b_MSU_essay|Paragraph_2|Data|130,443</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(130, 443)</td>\n",
       "      <td>The first time a person learns that a certain ...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>9b_MSU_essay|Paragraph_3|Primary_Claim|0,170</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(0, 170)</td>\n",
       "      <td>It is hard for people to develop new original ...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_1|Final_Claim|142,726</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128; Paragraph_4|P...</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>9b_MSU_essay|Paragraph_3|Data|172,489</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(172, 489)</td>\n",
       "      <td>For example, producers of TV shows strive to p...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_3|Primary_Claim|0,170</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>9b_MSU_essay|Paragraph_4|Primary_Claim|0,174</td>\n",
       "      <td>Paragraph_4</td>\n",
       "      <td>(0, 174)</td>\n",
       "      <td>Almost every product one can think of has alre...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_1|Final_Claim|142,726</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128; Paragraph_3|P...</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>9b_MSU_essay|Paragraph_4|Data|176,368</td>\n",
       "      <td>Paragraph_4</td>\n",
       "      <td>(176, 368)</td>\n",
       "      <td>For example, video game consoles have been aro...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_4|Primary_Claim|0,174</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       discourse_id discourse_part  \\\n",
       "0         1_MSU_essay|Paragraph_1|Nonannotated|0,20    Paragraph_1   \n",
       "1        1_MSU_essay|Paragraph_2|Nonannotated|0,565    Paragraph_2   \n",
       "2       1_MSU_essay|Paragraph_2|Final_Claim|567,660    Paragraph_2   \n",
       "3                1_MSU_essay|Paragraph_3|Data|0,519    Paragraph_3   \n",
       "4     1_MSU_essay|Paragraph_3|Primary_Claim|521,628    Paragraph_3   \n",
       "...                                             ...            ...   \n",
       "2259          9b_MSU_essay|Paragraph_2|Data|130,443    Paragraph_2   \n",
       "2260   9b_MSU_essay|Paragraph_3|Primary_Claim|0,170    Paragraph_3   \n",
       "2261          9b_MSU_essay|Paragraph_3|Data|172,489    Paragraph_3   \n",
       "2262   9b_MSU_essay|Paragraph_4|Primary_Claim|0,174    Paragraph_4   \n",
       "2263          9b_MSU_essay|Paragraph_4|Data|176,368    Paragraph_4   \n",
       "\n",
       "     discourse_boundary                                     discourse_text  \\\n",
       "0               (0, 20)                              Heroes or Celebrities   \n",
       "1              (0, 565)  Celebrities and heroes are often confused in t...   \n",
       "2            (567, 660)  This idea of a hero has been forgotten and sho...   \n",
       "3              (0, 519)  How does one define a hero? Is it because of t...   \n",
       "4            (521, 628)  Although many people do heroic things, they ar...   \n",
       "...                 ...                                                ...   \n",
       "2259         (130, 443)  The first time a person learns that a certain ...   \n",
       "2260           (0, 170)  It is hard for people to develop new original ...   \n",
       "2261         (172, 489)  For example, producers of TV shows strive to p...   \n",
       "2262           (0, 174)  Almost every product one can think of has alre...   \n",
       "2263         (176, 368)  For example, video game consoles have been aro...   \n",
       "\n",
       "     adjudicated_discourse_type adjudicated_effectiveness  \\\n",
       "0                  Nonannotated                         -   \n",
       "1                  Nonannotated                         -   \n",
       "2                   Final_Claim                  adequate   \n",
       "3                          Data                 effective   \n",
       "4                 Primary_Claim                 effective   \n",
       "...                         ...                       ...   \n",
       "2259                       Data                  adequate   \n",
       "2260              Primary_Claim                  adequate   \n",
       "2261                       Data                  adequate   \n",
       "2262              Primary_Claim                  adequate   \n",
       "2263                       Data                  adequate   \n",
       "\n",
       "               adjudicated_hierarchical  \\\n",
       "0                                     -   \n",
       "1                                     -   \n",
       "2                                     -   \n",
       "3     Paragraph_3|Primary_Claim|521,628   \n",
       "4       Paragraph_2|Final_Claim|567,660   \n",
       "...                                 ...   \n",
       "2259    Paragraph_2|Primary_Claim|0,128   \n",
       "2260    Paragraph_1|Final_Claim|142,726   \n",
       "2261    Paragraph_3|Primary_Claim|0,170   \n",
       "2262    Paragraph_1|Final_Claim|142,726   \n",
       "2263    Paragraph_4|Primary_Claim|0,174   \n",
       "\n",
       "                                   adjudicated_parallel         essay  score  \n",
       "0                                                     -   1_MSU_essay    5.0  \n",
       "1                                                     -   1_MSU_essay    5.0  \n",
       "2                                                     -   1_MSU_essay    5.0  \n",
       "3                                                     -   1_MSU_essay    5.0  \n",
       "4                     Paragraph_4|Primary_Claim|449,553   1_MSU_essay    5.0  \n",
       "...                                                 ...           ...    ...  \n",
       "2259                                                  -  9b_MSU_essay    3.5  \n",
       "2260  Paragraph_2|Primary_Claim|0,128; Paragraph_4|P...  9b_MSU_essay    3.5  \n",
       "2261                                                  -  9b_MSU_essay    3.5  \n",
       "2262  Paragraph_2|Primary_Claim|0,128; Paragraph_3|P...  9b_MSU_essay    3.5  \n",
       "2263                                                  -  9b_MSU_essay    3.5  \n",
       "\n",
       "[2264 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot = pd.concat(all_essays, ignore_index=True)\n",
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_sifr = GPT2PPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_sifr.getPPL(annot['discourse_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot['ppl'] = annot['discourse_text'].apply(gpt_sifr.getPPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot.to_csv(f\"{DATADIR}/AnnotsWithPPL.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For uploading to GPTZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_essays(essays, folder = \"Exports\", extension = \"txt\"):\n",
    "    assert 'Text' in essays.columns\n",
    "\n",
    "    def export(row):\n",
    "        filename = os.path.join(DATADIR, folder, f\"{row['Essay']}.{extension}\")\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(row['Text'])\n",
    "    \n",
    "    essays.apply(export, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_essays(essays)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPTZero\n",
    "\n",
    "The class GPTZeroAPI comes courtesy of https://github.com/Haste171/gptzero.\n",
    "\n",
    "See https://gptzero.me/docs for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTZeroAPI:\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = 'https://api.gptzero.me/v2/predict'\n",
    "    \n",
    "    def text_predict(self, document):\n",
    "        url = f'{self.base_url}/text'\n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'X-Api-Key': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        data = {\n",
    "            'document': document\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        return response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tayyab and Chua's Implementation\n",
    "\n",
    "GPTZero costs money to use the API :(\n",
    "\n",
    "Let's try this version instead, where Tayyab and Chua attempt to imitate\n",
    "GPTZero's methods. They claim that they achieve the same results.\n",
    "\n",
    "https://github.com/BurhanUlTayyab/GPTZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SadPrograms\\anaconda\\envs\\openai\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2PPL:\n",
    "\n",
    "    def __init__(self, device = \"cpu\", model_id = \"gpt2\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "        self.max_length = self.model.config.n_positions\n",
    "        self.stride = 512\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        \"\"\"Take a sentence split by full stop and print perplexity.\n",
    "        \n",
    "        Burstiness is the max perplexity of each sentence.\n",
    "        \"\"\"\n",
    "        results = OrderedDict()\n",
    "\n",
    "        total_valid_char = re.findall(\"[a-zA-Z0-9]+\", sentence)\n",
    "        total_valid_char = sum([len(x) for x in total_valid_char])\n",
    "\n",
    "        # print(total_valid_char)\n",
    "        # assert total_valid_char >= 100\n",
    "        if total_valid_char < 100:\n",
    "            return\n",
    "\n",
    "        lines = re.split(r'(?<=[.?!][ \\[\\(])|(?<=\\n)\\s*', sentence)\n",
    "        lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))\n",
    "\n",
    "        ppl = self.getPPL(sentence)\n",
    "        results['perplexity'] = ppl\n",
    "\n",
    "        offset = \"\"\n",
    "        ppl_per_line = []\n",
    "        for line in lines:\n",
    "            if re.search(\"[a-zA-Z0-9]+\", line) == None:\n",
    "                continue\n",
    "            if len(offset) > 0:\n",
    "                line = offset + line\n",
    "                offset = \"\"\n",
    "            \n",
    "            # remove the new line or space in the first sentence if it exists\n",
    "            if line[0] == '\\n' or line[0] == ' ':\n",
    "                line = line[1:]\n",
    "            if line[-1] == '\\n' or line[-1] == ' ':\n",
    "                line = line[:-1]\n",
    "            elif line[-1] == '[' or line[-1] == '(':\n",
    "                offset = line[-1]\n",
    "                line = line[:-1]\n",
    "            \n",
    "            ppl = self.getPPL(line)\n",
    "            ppl_per_line.append(ppl)\n",
    "    \n",
    "        results['ppl_per_line'] = sum(ppl_per_line) / len(ppl_per_line)\n",
    "        results['burstiness'] = max(ppl_per_line)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def getPPL(self, sentence):\n",
    "        encodings = self.tokenizer(sentence, return_tensors = \"pt\")\n",
    "        seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "        nlls = []\n",
    "        likelihoods = []\n",
    "        prev_end_loc = 0\n",
    "        for begin_loc in range(0, seq_len, self.stride):\n",
    "            end_loc = min(begin_loc + self.max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc\n",
    "            input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids, labels = target_ids)\n",
    "                neg_log_likelihood = outputs.loss * trg_len\n",
    "                likelihoods.append(neg_log_likelihood)\n",
    "            \n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "        \n",
    "        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))\n",
    "        return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_sifr = GPT2PPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('perplexity', 21),\n",
       "             ('ppl_per_line', 64.375),\n",
       "             ('burstiness', 421)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_sifr(essays['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePPL(text):\n",
    "    data = gpt_sifr(text)\n",
    "    return data['ppl_per_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays['LinePPL'] = essays['Text'].apply(averagePPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay</th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Holistic Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>LinePPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>426</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Heroes or Celebrities\\nCelebrities and heroes ...</td>\n",
       "      <td>64.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_MSU_essay</td>\n",
       "      <td>262</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Musicians, artists, writers, scientists, and m...</td>\n",
       "      <td>46.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_MSU_essay</td>\n",
       "      <td>191</td>\n",
       "      <td>2.5</td>\n",
       "      <td>People have the freedom to choose what they wa...</td>\n",
       "      <td>73.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100b_MSU_essay</td>\n",
       "      <td>233</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Anyone can become a celebrity, but to become a...</td>\n",
       "      <td>69.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_MSU_essay</td>\n",
       "      <td>365</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Most people at a young age have those certain ...</td>\n",
       "      <td>94.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>98_MSU_essay</td>\n",
       "      <td>542</td>\n",
       "      <td>4.5</td>\n",
       "      <td>In our modern day society, it has become commo...</td>\n",
       "      <td>46.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>98b_MSU_essay</td>\n",
       "      <td>480</td>\n",
       "      <td>4.0</td>\n",
       "      <td>In an age of celebrity worship, where movie st...</td>\n",
       "      <td>71.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>99_MSU_essay</td>\n",
       "      <td>357</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A limo pulls up, cameras are constantly flashi...</td>\n",
       "      <td>60.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>99b_MSU_essay</td>\n",
       "      <td>378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Heroes and celebrities are clearly different. ...</td>\n",
       "      <td>57.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>358</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Originality is purely a measure of what one kn...</td>\n",
       "      <td>46.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Essay   Number of words  Holistic Score  \\\n",
       "0       1_MSU_essay               426             5.0   \n",
       "1      10_MSU_essay               262             3.5   \n",
       "2     100_MSU_essay               191             2.5   \n",
       "3    100b_MSU_essay               233             3.5   \n",
       "4     101_MSU_essay               365             1.5   \n",
       "..              ...               ...             ...   \n",
       "309    98_MSU_essay               542             4.5   \n",
       "310   98b_MSU_essay               480             4.0   \n",
       "311    99_MSU_essay               357             2.5   \n",
       "312   99b_MSU_essay               378             2.0   \n",
       "313    9b_MSU_essay               358             3.5   \n",
       "\n",
       "                                                  Text    LinePPL  \n",
       "0    Heroes or Celebrities\\nCelebrities and heroes ...  64.375000  \n",
       "1    Musicians, artists, writers, scientists, and m...  46.083333  \n",
       "2    People have the freedom to choose what they wa...  73.214286  \n",
       "3    Anyone can become a celebrity, but to become a...  69.727273  \n",
       "4    Most people at a young age have those certain ...  94.900000  \n",
       "..                                                 ...        ...  \n",
       "309  In our modern day society, it has become commo...  46.407407  \n",
       "310  In an age of celebrity worship, where movie st...  71.562500  \n",
       "311  A limo pulls up, cameras are constantly flashi...  60.941176  \n",
       "312  Heroes and celebrities are clearly different. ...  57.136364  \n",
       "313  Originality is purely a measure of what one kn...  46.687500  \n",
       "\n",
       "[314 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays.to_csv(os.path.join(DATADIR, \"EssaysWithPPL.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Difference between GPTZero and TayyabChua\n",
    "\n",
    "(Written 6pm, 4/2/2023)\n",
    "\n",
    "The TayyabChua algorithm is identifying as many essays as being as human-written as they are AI-generated. This is a mistake, as all of the essays were human-written. Is this an issue of GPTZero having a lot of false positives, or is it an issue of TayyabChua's implementation being imperfect?\n",
    "\n",
    "To test this, I am grabbing a random sample of 30 human-written essays from the Claim Identifican Corpus and finding their scores for both GPTZero and TayyabChua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SadPrograms\\anaconda\\envs\\openai\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\n",
      "v ggplot2 3.3.5     v purrr   0.3.4\n",
      "v tibble  3.1.8     v dplyr   1.0.8\n",
      "v tidyr   1.2.0     v stringr 1.4.0\n",
      "v readr   2.1.2     v forcats 0.5.1\n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: 'magrittr'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:purrr':\n",
      "\n",
      "    set_names\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:tidyr':\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'janitor'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    chisq.test, fisher.test\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(tidyverse)  # for data manipulation and cleanup\n",
    "library(magrittr)   # for %>%\n",
    "library(stats)      # for qqnorm, qqplot\n",
    "library(janitor)\n",
    "\n",
    "setwd(\"D:/data/claim_identification_corpus\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1\n",
    "\n",
    "We expect the result for the TayyabChua to be exactly the same as the result for GPTZero for every essay.\n",
    "\n",
    "$H_0: p_\\text{same} = 0$\n",
    "\n",
    "$H_\\alpha: p_\\text{same} > 0$\n",
    "\n",
    "$p_\\text{same}$ is the proportion of all essays in the Claim Identification Corpus that have the exact same perplexity score between GPTZero and TayyabChua (rounded to the nearest whole number)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 30\n",
      "Columns: 6\n",
      "$ X          <int> 19, 24, 36, 38, 39, 41, 43, 69, 78, 84, 88, 104, 110, 120, ~\n",
      "$ filename   <chr> \"108b_MSU_essay\", \"111_MSU_essay\", \"125_MSU_essay\", \"126_MS~\n",
      "$ nwords     <int> 523, 308, 449, 351, 544, 387, 285, 261, 264, 398, 179, 348,~\n",
      "$ score      <dbl> 3.0, 4.0, 2.5, 2.0, 4.0, 4.5, 4.5, 4.0, 5.0, 3.5, 3.5, 3.0,~\n",
      "$ text       <chr> \"Heroes are those select people that we should look up to a~\n",
      "$ tayyabchao <dbl> 66.68000, 104.45000, 98.80000, 79.16000, 110.80488, 91.0625~\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(0)\n",
    "\n",
    "df <- read.csv(\"EssaysWithPPL.csv\") %>%\n",
    "    rename(filename = Essay,\n",
    "           nwords = Number.of.words,\n",
    "           score = Holistic.Score,\n",
    "           text = Text,\n",
    "           tayyabchao = LinePPL)\n",
    "\n",
    "rows <- df %>%\n",
    "    nrow %>%\n",
    "    sample(size=30) %>%\n",
    "    sort\n",
    "df <- df[rows, ]\n",
    "\n",
    "write.csv(df[c(\"filename\", \"tayyabchao\")], file='RandomSample.csv',\n",
    "          quote=FALSE)\n",
    "\n",
    "glimpse(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files selected in the random sample were uploaded, one-by-one and manually, into the website app.gptzero.me/app/welcome. The average perplexity scores, burtiness scores, highest perplexities, and overall decisions were manually recorded in the file \"RandomSampleWithGPTZero.csv\".\n",
    "\n",
    "Notes:\n",
    " - The essay \"18b_MSU_essay\" has a TayyabChao score of 54.35 and a GPTZero score of 53.350. This is not a typo.\n",
    " - The qualitative category \"Your text may include parts written by an AI.\" seems to partition the analyzed text in a way that is out of the scope of Tayyab & Chao's algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 30\n",
      "Columns: 7\n",
      "$ X          <int> 20, 25, 37, 39, 40, 42, 44, 70, 79, 85, 89, 105, 111, 121, ~\n",
      "$ filename   <chr> \"108b_MSU_essay\", \"111_MSU_essay\", \"125_MSU_essay\", \"126_MS~\n",
      "$ tayyabchao <dbl> 66.68000, 104.45000, 98.80000, 79.16000, 110.80488, 91.0625~\n",
      "$ gptzero    <dbl> 66.680, 104.450, 98.800, 79.160, 112.850, 91.063, 71.200, 3~\n",
      "$ burstiness <dbl> 61.515, 83.414, 98.235, 72.862, 150.151, 77.658, 32.601, 18~\n",
      "$ decision   <chr> \"Your text is likely to be written entirely by a human.\", \"~\n",
      "$ highestppl <int> 305, 283, 475, 333, 782, 288, 134, 75, 254, 182, 180, 247, ~\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "df <- read.csv(\"RandomSampleWithGPTZero.csv\")\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.2333333\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "df$exactmatch <- janitor::round_half_up(df$tayyabchao) == janitor::round_half_up(df$gptzero)\n",
    "prop <- sum(!df$exactmatch) / nrow(df)\n",
    "prop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of essays in this random sample that do not have the same perplexity scores between GPTZero and the TayyabChao algorithm is 23.33%. This value is, well, greater than 0%, so we can be sure that the TayyabChao algorithm does not exactly match GPTZero's scores.\n",
    "\n",
    "Perhaps it would be worthwhile to find out what the distribution of differences looks like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Difference Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd expect the perplexities given by TayyabChao and GPTZero to at least be similar. Therefore, we predict that the difference between the perplexity for a given essay as determined by TayyabChao and the perplexity determined by GPTZero is approximately 0.\n",
    "\n",
    "$H_0: \\mu_d = 0$\n",
    "\n",
    "$H_\\alpha: \\mu_d \\neq 0$\n",
    "\n",
    "$\\mu_d$ is the average difference between the TayyabChao perplexity and the GPTZero perplexity for each essay in the Claim Identification Corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "df$difference <- df$gptzero - df$tayyabchao\n",
    "hist(df$difference,\n",
    "     main = \"Histogram of Perplexity Differences\",\n",
    "     xlab = \"GPTZero - TayyabChao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "qqnorm(df$difference, main = \"Q-Q Plot of Perplexity Differences\")\n",
    "qqline(df$difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPaired t-test\n",
      "\n",
      "data:  df$gptzero and df$tayyabchao\n",
      "t = -1.2757, df = 29, p-value = 0.2122\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "99 percent confidence interval:\n",
      " -0.9710903  0.3566243\n",
      "sample estimates:\n",
      "mean of the differences \n",
      "              -0.307233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "t.test(x = df$gptzero, y = df$tayyabchao,\n",
    "       alternative = \"two.sided\", mu = 0, paired = TRUE, conf.level = 0.99)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the resuling p-value of 0.2122, there is not enough evidence to reject the null hypothesis that $\\mu_d = 0$. Furthermore, we can expect 99% of all differences to be between -0.97 and 0.36, so the difference between GPTZero and TayyabChao's perplexities should be negligible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
