{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = r\"D:\\data\\claim_identification_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = pd.read_excel(os.path.join(DATADIR, \"essay_scores.xlsx\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay(filename):\n",
    "    df = pd.read_csv(os.path.join(DATADIR, \"Data\", filename + \".csv\"))\n",
    "\n",
    "    res = []\n",
    "\n",
    "    ind_para = 1\n",
    "    while ind_para < len(df):\n",
    "        this_para = df['discourse_part'] == \"Paragraph_\" + str(ind_para)\n",
    "        if not any(this_para):\n",
    "            break\n",
    "        text = ' '.join(df['discourse_text'][this_para])\n",
    "        res.append(text)\n",
    "        ind_para += 1\n",
    "    \n",
    "    return '\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays['Text'] = essays['Essay'].apply(get_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4273"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(essays['Text'].apply(len))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Essays by Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = []\n",
    "\n",
    "for i, row in essays.iterrows():\n",
    "    try:\n",
    "        filepath = f\"{DATADIR}/Data/{row['Essay']}.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    df['essay'] = row['Essay']\n",
    "    df['score'] = row['Holistic Score']\n",
    "\n",
    "    all_essays.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_part</th>\n",
       "      <th>discourse_boundary</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>adjudicated_discourse_type</th>\n",
       "      <th>adjudicated_effectiveness</th>\n",
       "      <th>adjudicated_hierarchical</th>\n",
       "      <th>adjudicated_parallel</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_MSU_essay|Paragraph_1|Nonannotated|0,20</td>\n",
       "      <td>Paragraph_1</td>\n",
       "      <td>(0, 20)</td>\n",
       "      <td>Heroes or Celebrities</td>\n",
       "      <td>Nonannotated</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_MSU_essay|Paragraph_2|Nonannotated|0,565</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(0, 565)</td>\n",
       "      <td>Celebrities and heroes are often confused in t...</td>\n",
       "      <td>Nonannotated</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_MSU_essay|Paragraph_2|Final_Claim|567,660</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(567, 660)</td>\n",
       "      <td>This idea of a hero has been forgotten and sho...</td>\n",
       "      <td>Final_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_MSU_essay|Paragraph_3|Data|0,519</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(0, 519)</td>\n",
       "      <td>How does one define a hero? Is it because of t...</td>\n",
       "      <td>Data</td>\n",
       "      <td>effective</td>\n",
       "      <td>Paragraph_3|Primary_Claim|521,628</td>\n",
       "      <td>-</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_MSU_essay|Paragraph_3|Primary_Claim|521,628</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(521, 628)</td>\n",
       "      <td>Although many people do heroic things, they ar...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>effective</td>\n",
       "      <td>Paragraph_2|Final_Claim|567,660</td>\n",
       "      <td>Paragraph_4|Primary_Claim|449,553</td>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>9b_MSU_essay|Paragraph_2|Data|130,443</td>\n",
       "      <td>Paragraph_2</td>\n",
       "      <td>(130, 443)</td>\n",
       "      <td>The first time a person learns that a certain ...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>9b_MSU_essay|Paragraph_3|Primary_Claim|0,170</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(0, 170)</td>\n",
       "      <td>It is hard for people to develop new original ...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_1|Final_Claim|142,726</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128; Paragraph_4|P...</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>9b_MSU_essay|Paragraph_3|Data|172,489</td>\n",
       "      <td>Paragraph_3</td>\n",
       "      <td>(172, 489)</td>\n",
       "      <td>For example, producers of TV shows strive to p...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_3|Primary_Claim|0,170</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>9b_MSU_essay|Paragraph_4|Primary_Claim|0,174</td>\n",
       "      <td>Paragraph_4</td>\n",
       "      <td>(0, 174)</td>\n",
       "      <td>Almost every product one can think of has alre...</td>\n",
       "      <td>Primary_Claim</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_1|Final_Claim|142,726</td>\n",
       "      <td>Paragraph_2|Primary_Claim|0,128; Paragraph_3|P...</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>9b_MSU_essay|Paragraph_4|Data|176,368</td>\n",
       "      <td>Paragraph_4</td>\n",
       "      <td>(176, 368)</td>\n",
       "      <td>For example, video game consoles have been aro...</td>\n",
       "      <td>Data</td>\n",
       "      <td>adequate</td>\n",
       "      <td>Paragraph_4|Primary_Claim|0,174</td>\n",
       "      <td>-</td>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       discourse_id discourse_part  \\\n",
       "0         1_MSU_essay|Paragraph_1|Nonannotated|0,20    Paragraph_1   \n",
       "1        1_MSU_essay|Paragraph_2|Nonannotated|0,565    Paragraph_2   \n",
       "2       1_MSU_essay|Paragraph_2|Final_Claim|567,660    Paragraph_2   \n",
       "3                1_MSU_essay|Paragraph_3|Data|0,519    Paragraph_3   \n",
       "4     1_MSU_essay|Paragraph_3|Primary_Claim|521,628    Paragraph_3   \n",
       "...                                             ...            ...   \n",
       "2259          9b_MSU_essay|Paragraph_2|Data|130,443    Paragraph_2   \n",
       "2260   9b_MSU_essay|Paragraph_3|Primary_Claim|0,170    Paragraph_3   \n",
       "2261          9b_MSU_essay|Paragraph_3|Data|172,489    Paragraph_3   \n",
       "2262   9b_MSU_essay|Paragraph_4|Primary_Claim|0,174    Paragraph_4   \n",
       "2263          9b_MSU_essay|Paragraph_4|Data|176,368    Paragraph_4   \n",
       "\n",
       "     discourse_boundary                                     discourse_text  \\\n",
       "0               (0, 20)                              Heroes or Celebrities   \n",
       "1              (0, 565)  Celebrities and heroes are often confused in t...   \n",
       "2            (567, 660)  This idea of a hero has been forgotten and sho...   \n",
       "3              (0, 519)  How does one define a hero? Is it because of t...   \n",
       "4            (521, 628)  Although many people do heroic things, they ar...   \n",
       "...                 ...                                                ...   \n",
       "2259         (130, 443)  The first time a person learns that a certain ...   \n",
       "2260           (0, 170)  It is hard for people to develop new original ...   \n",
       "2261         (172, 489)  For example, producers of TV shows strive to p...   \n",
       "2262           (0, 174)  Almost every product one can think of has alre...   \n",
       "2263         (176, 368)  For example, video game consoles have been aro...   \n",
       "\n",
       "     adjudicated_discourse_type adjudicated_effectiveness  \\\n",
       "0                  Nonannotated                         -   \n",
       "1                  Nonannotated                         -   \n",
       "2                   Final_Claim                  adequate   \n",
       "3                          Data                 effective   \n",
       "4                 Primary_Claim                 effective   \n",
       "...                         ...                       ...   \n",
       "2259                       Data                  adequate   \n",
       "2260              Primary_Claim                  adequate   \n",
       "2261                       Data                  adequate   \n",
       "2262              Primary_Claim                  adequate   \n",
       "2263                       Data                  adequate   \n",
       "\n",
       "               adjudicated_hierarchical  \\\n",
       "0                                     -   \n",
       "1                                     -   \n",
       "2                                     -   \n",
       "3     Paragraph_3|Primary_Claim|521,628   \n",
       "4       Paragraph_2|Final_Claim|567,660   \n",
       "...                                 ...   \n",
       "2259    Paragraph_2|Primary_Claim|0,128   \n",
       "2260    Paragraph_1|Final_Claim|142,726   \n",
       "2261    Paragraph_3|Primary_Claim|0,170   \n",
       "2262    Paragraph_1|Final_Claim|142,726   \n",
       "2263    Paragraph_4|Primary_Claim|0,174   \n",
       "\n",
       "                                   adjudicated_parallel         essay  score  \n",
       "0                                                     -   1_MSU_essay    5.0  \n",
       "1                                                     -   1_MSU_essay    5.0  \n",
       "2                                                     -   1_MSU_essay    5.0  \n",
       "3                                                     -   1_MSU_essay    5.0  \n",
       "4                     Paragraph_4|Primary_Claim|449,553   1_MSU_essay    5.0  \n",
       "...                                                 ...           ...    ...  \n",
       "2259                                                  -  9b_MSU_essay    3.5  \n",
       "2260  Paragraph_2|Primary_Claim|0,128; Paragraph_4|P...  9b_MSU_essay    3.5  \n",
       "2261                                                  -  9b_MSU_essay    3.5  \n",
       "2262  Paragraph_2|Primary_Claim|0,128; Paragraph_3|P...  9b_MSU_essay    3.5  \n",
       "2263                                                  -  9b_MSU_essay    3.5  \n",
       "\n",
       "[2264 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot = pd.concat(all_essays, ignore_index=True)\n",
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_sifr = GPT2PPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_sifr.getPPL(annot['discourse_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot['ppl'] = annot['discourse_text'].apply(gpt_sifr.getPPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot.to_csv(f\"{DATADIR}/AnnotsWithPPL.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For uploading to GPTZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_essays(essays, folder = \"Exports\", extension = \"txt\"):\n",
    "    assert 'Text' in essays.columns\n",
    "\n",
    "    def export(row):\n",
    "        filename = os.path.join(DATADIR, folder, f\"{row['Essay']}.{extension}\")\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(row['Text'])\n",
    "    \n",
    "    essays.apply(export, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_essays(essays)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPTZero\n",
    "\n",
    "The class GPTZeroAPI comes courtesy of https://github.com/Haste171/gptzero.\n",
    "\n",
    "See https://gptzero.me/docs for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTZeroAPI:\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = 'https://api.gptzero.me/v2/predict'\n",
    "    \n",
    "    def text_predict(self, document):\n",
    "        url = f'{self.base_url}/text'\n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'X-Api-Key': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        data = {\n",
    "            'document': document\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        return response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tayyab and Chua's Implementation\n",
    "\n",
    "GPTZero costs money to use the API :(\n",
    "\n",
    "Let's try this version instead, where Tayyab and Chua attempt to imitate\n",
    "GPTZero's methods. They claim that they achieve the same results.\n",
    "\n",
    "https://github.com/BurhanUlTayyab/GPTZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SadPrograms\\anaconda\\envs\\openai\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2PPL:\n",
    "\n",
    "    def __init__(self, device = \"cpu\", model_id = \"gpt2\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "        self.max_length = self.model.config.n_positions\n",
    "        self.stride = 512\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        \"\"\"Take a sentence split by full stop and print perplexity.\n",
    "        \n",
    "        Burstiness is the max perplexity of each sentence.\n",
    "        \"\"\"\n",
    "        results = OrderedDict()\n",
    "\n",
    "        total_valid_char = re.findall(\"[a-zA-Z0-9]+\", sentence)\n",
    "        total_valid_char = sum([len(x) for x in total_valid_char])\n",
    "\n",
    "        # print(total_valid_char)\n",
    "        # assert total_valid_char >= 100\n",
    "        if total_valid_char < 100:\n",
    "            return\n",
    "\n",
    "        lines = re.split(r'(?<=[.?!][ \\[\\(])|(?<=\\n)\\s*', sentence)\n",
    "        lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))\n",
    "\n",
    "        ppl = self.getPPL(sentence)\n",
    "        results['perplexity'] = ppl\n",
    "\n",
    "        offset = \"\"\n",
    "        ppl_per_line = []\n",
    "        for line in lines:\n",
    "            if re.search(\"[a-zA-Z0-9]+\", line) == None:\n",
    "                continue\n",
    "            if len(offset) > 0:\n",
    "                line = offset + line\n",
    "                offset = \"\"\n",
    "            \n",
    "            # remove the new line or space in the first sentence if it exists\n",
    "            if line[0] == '\\n' or line[0] == ' ':\n",
    "                line = line[1:]\n",
    "            if line[-1] == '\\n' or line[-1] == ' ':\n",
    "                line = line[:-1]\n",
    "            elif line[-1] == '[' or line[-1] == '(':\n",
    "                offset = line[-1]\n",
    "                line = line[:-1]\n",
    "            \n",
    "            ppl = self.getPPL(line)\n",
    "            ppl_per_line.append(ppl)\n",
    "    \n",
    "        results['ppl_per_line'] = sum(ppl_per_line) / len(ppl_per_line)\n",
    "        results['burstiness'] = max(ppl_per_line)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def getPPL(self, sentence):\n",
    "        encodings = self.tokenizer(sentence, return_tensors = \"pt\")\n",
    "        seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "        nlls = []\n",
    "        likelihoods = []\n",
    "        prev_end_loc = 0\n",
    "        for begin_loc in range(0, seq_len, self.stride):\n",
    "            end_loc = min(begin_loc + self.max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc\n",
    "            input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids, labels = target_ids)\n",
    "                neg_log_likelihood = outputs.loss * trg_len\n",
    "                likelihoods.append(neg_log_likelihood)\n",
    "            \n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "        \n",
    "        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))\n",
    "        return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_sifr = GPT2PPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('perplexity', 21),\n",
       "             ('ppl_per_line', 64.375),\n",
       "             ('burstiness', 421)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_sifr(essays['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePPL(text):\n",
    "    data = gpt_sifr(text)\n",
    "    return data['ppl_per_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965\n",
      "1334\n",
      "939\n",
      "1046\n",
      "1670\n",
      "1177\n",
      "1662\n",
      "1419\n",
      "1989\n",
      "935\n",
      "997\n",
      "1462\n",
      "892\n",
      "2137\n",
      "1411\n",
      "1429\n",
      "735\n",
      "3068\n",
      "2952\n",
      "2253\n",
      "1164\n",
      "2574\n",
      "2251\n",
      "1141\n",
      "1391\n",
      "1768\n",
      "1977\n",
      "1277\n",
      "1178\n",
      "1957\n",
      "2237\n",
      "2096\n",
      "1484\n",
      "795\n",
      "1721\n",
      "1736\n",
      "1872\n",
      "1693\n",
      "1538\n",
      "2472\n",
      "736\n",
      "1739\n",
      "1240\n",
      "1222\n",
      "1992\n",
      "1989\n",
      "1417\n",
      "1159\n",
      "2102\n",
      "1528\n",
      "1606\n",
      "1035\n",
      "2318\n",
      "1486\n",
      "2200\n",
      "1380\n",
      "1617\n",
      "536\n",
      "1489\n",
      "1055\n",
      "763\n",
      "1404\n",
      "1141\n",
      "2199\n",
      "1835\n",
      "1568\n",
      "1492\n",
      "1075\n",
      "1579\n",
      "1129\n",
      "651\n",
      "1158\n",
      "2129\n",
      "983\n",
      "1465\n",
      "1460\n",
      "1735\n",
      "2582\n",
      "1236\n",
      "1330\n",
      "891\n",
      "1086\n",
      "2289\n",
      "1046\n",
      "1741\n",
      "2307\n",
      "792\n",
      "2336\n",
      "799\n",
      "1500\n",
      "1119\n",
      "1381\n",
      "2881\n",
      "1260\n",
      "1796\n",
      "1960\n",
      "1933\n",
      "2262\n",
      "1275\n",
      "1269\n",
      "1829\n",
      "1966\n",
      "1217\n",
      "2754\n",
      "1523\n",
      "1384\n",
      "3061\n",
      "2246\n",
      "2314\n",
      "2655\n",
      "1224\n",
      "963\n",
      "1049\n",
      "1352\n",
      "1581\n",
      "1504\n",
      "2479\n",
      "1483\n",
      "2422\n",
      "723\n",
      "1890\n",
      "1910\n",
      "1602\n",
      "1261\n",
      "1651\n",
      "1189\n",
      "1536\n",
      "1660\n",
      "1424\n",
      "2271\n",
      "689\n",
      "1003\n",
      "1438\n",
      "1313\n",
      "1962\n",
      "1445\n",
      "1287\n",
      "2056\n",
      "1021\n",
      "1982\n",
      "2268\n",
      "1230\n",
      "969\n",
      "730\n",
      "1970\n",
      "1049\n",
      "2241\n",
      "1110\n",
      "1962\n",
      "2103\n",
      "1032\n",
      "1280\n",
      "1684\n",
      "729\n",
      "706\n",
      "2224\n",
      "2041\n",
      "997\n",
      "1722\n",
      "1214\n",
      "1795\n",
      "1214\n",
      "1109\n",
      "1121\n",
      "1528\n",
      "1653\n",
      "1234\n",
      "1727\n",
      "2664\n",
      "1381\n",
      "2385\n",
      "1606\n",
      "1174\n",
      "1334\n",
      "895\n",
      "1450\n",
      "1338\n",
      "1492\n",
      "1389\n",
      "790\n",
      "1624\n",
      "1573\n",
      "1271\n",
      "1096\n",
      "868\n",
      "2647\n",
      "1640\n",
      "1081\n",
      "703\n",
      "2392\n",
      "1922\n",
      "1435\n",
      "1328\n",
      "1411\n",
      "1709\n",
      "1286\n",
      "2079\n",
      "1864\n",
      "2554\n",
      "2771\n",
      "1182\n",
      "1127\n",
      "2074\n",
      "1645\n",
      "2215\n",
      "1670\n",
      "1872\n",
      "1107\n",
      "1443\n",
      "1399\n",
      "2122\n",
      "1584\n",
      "1369\n",
      "825\n",
      "2403\n",
      "1622\n",
      "2154\n",
      "1488\n",
      "1365\n",
      "2229\n",
      "1783\n",
      "542\n",
      "1482\n",
      "1860\n",
      "1233\n",
      "948\n",
      "1445\n",
      "1469\n",
      "743\n",
      "1434\n",
      "1687\n",
      "1929\n",
      "997\n",
      "1481\n",
      "2536\n",
      "1000\n",
      "1500\n",
      "1687\n",
      "1587\n",
      "2080\n",
      "1965\n",
      "965\n",
      "1181\n",
      "2005\n",
      "1203\n",
      "1738\n",
      "1207\n",
      "894\n",
      "1552\n",
      "954\n",
      "771\n",
      "1359\n",
      "1028\n",
      "2046\n",
      "771\n",
      "1065\n",
      "1614\n",
      "1782\n",
      "1692\n",
      "959\n",
      "1831\n",
      "2125\n",
      "1092\n",
      "1397\n",
      "2157\n",
      "2048\n",
      "2023\n",
      "1624\n",
      "1545\n",
      "2078\n",
      "1428\n",
      "1266\n",
      "2497\n",
      "1875\n",
      "2714\n",
      "2297\n",
      "687\n",
      "2146\n",
      "1515\n",
      "2126\n",
      "1776\n",
      "2392\n",
      "1152\n",
      "1969\n",
      "1638\n",
      "1885\n",
      "2028\n",
      "2012\n",
      "811\n",
      "1530\n",
      "1225\n",
      "893\n",
      "2013\n",
      "3418\n",
      "1404\n",
      "1535\n",
      "1770\n",
      "1076\n",
      "1832\n",
      "1521\n",
      "1576\n",
      "2244\n",
      "1638\n",
      "926\n",
      "1513\n",
      "2009\n",
      "2002\n",
      "1008\n",
      "2219\n",
      "2459\n",
      "2300\n",
      "1582\n",
      "1667\n",
      "1639\n"
     ]
    }
   ],
   "source": [
    "essays['LinePPL'] = essays['Text'].apply(averagePPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay</th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Holistic Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>LinePPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_MSU_essay</td>\n",
       "      <td>426</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Heroes or Celebrities\\nCelebrities and heroes ...</td>\n",
       "      <td>64.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_MSU_essay</td>\n",
       "      <td>262</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Musicians, artists, writers, scientists, and m...</td>\n",
       "      <td>46.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_MSU_essay</td>\n",
       "      <td>191</td>\n",
       "      <td>2.5</td>\n",
       "      <td>People have the freedom to choose what they wa...</td>\n",
       "      <td>73.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100b_MSU_essay</td>\n",
       "      <td>233</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Anyone can become a celebrity, but to become a...</td>\n",
       "      <td>69.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_MSU_essay</td>\n",
       "      <td>365</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Most people at a young age have those certain ...</td>\n",
       "      <td>94.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>98_MSU_essay</td>\n",
       "      <td>542</td>\n",
       "      <td>4.5</td>\n",
       "      <td>In our modern day society, it has become commo...</td>\n",
       "      <td>46.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>98b_MSU_essay</td>\n",
       "      <td>480</td>\n",
       "      <td>4.0</td>\n",
       "      <td>In an age of celebrity worship, where movie st...</td>\n",
       "      <td>71.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>99_MSU_essay</td>\n",
       "      <td>357</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A limo pulls up, cameras are constantly flashi...</td>\n",
       "      <td>60.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>99b_MSU_essay</td>\n",
       "      <td>378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Heroes and celebrities are clearly different. ...</td>\n",
       "      <td>57.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9b_MSU_essay</td>\n",
       "      <td>358</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Originality is purely a measure of what one kn...</td>\n",
       "      <td>46.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Essay   Number of words  Holistic Score  \\\n",
       "0       1_MSU_essay               426             5.0   \n",
       "1      10_MSU_essay               262             3.5   \n",
       "2     100_MSU_essay               191             2.5   \n",
       "3    100b_MSU_essay               233             3.5   \n",
       "4     101_MSU_essay               365             1.5   \n",
       "..              ...               ...             ...   \n",
       "309    98_MSU_essay               542             4.5   \n",
       "310   98b_MSU_essay               480             4.0   \n",
       "311    99_MSU_essay               357             2.5   \n",
       "312   99b_MSU_essay               378             2.0   \n",
       "313    9b_MSU_essay               358             3.5   \n",
       "\n",
       "                                                  Text    LinePPL  \n",
       "0    Heroes or Celebrities\\nCelebrities and heroes ...  64.375000  \n",
       "1    Musicians, artists, writers, scientists, and m...  46.083333  \n",
       "2    People have the freedom to choose what they wa...  73.214286  \n",
       "3    Anyone can become a celebrity, but to become a...  69.727273  \n",
       "4    Most people at a young age have those certain ...  94.900000  \n",
       "..                                                 ...        ...  \n",
       "309  In our modern day society, it has become commo...  46.407407  \n",
       "310  In an age of celebrity worship, where movie st...  71.562500  \n",
       "311  A limo pulls up, cameras are constantly flashi...  60.941176  \n",
       "312  Heroes and celebrities are clearly different. ...  57.136364  \n",
       "313  Originality is purely a measure of what one kn...  46.687500  \n",
       "\n",
       "[314 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays.to_csv(os.path.join(DATADIR, \"EssaysWithPPL.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
